{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# pandas is a data analysis tool, contains object DataFrame\n",
    "import pandas as pd\n",
    "#import torch\n",
    "#\n",
    "import random\n",
    "\n",
    "# regex\n",
    "import re\n",
    "\n",
    "# datetime objects\n",
    "import datetime\n",
    "\n",
    "# plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# used for creating the dictionary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# used for flattening lists \n",
    "from itertools import chain\n",
    "from itertools import compress\n",
    "\n",
    "# NLTK and WordNet lemmatizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.core import Dense, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "import itertools\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "from keras.layers import Input, Dense, LSTM, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "import numpy as np \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load and evaluate a saved model\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from itertools import repeat\n",
    "from keras.callbacks import Callback\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pd.read_pickle(\"C:\\\\Users\\\\A373503\\\\Desktop\\\\Complete_4_models\\\\HDFS\\\\Data\\\\HDFS_train_mix_data.pkl\")\n",
    "word2id=pd.read_pickle('C:\\\\Users\\\\A373503\\\\Desktop\\\\Complete_4_models\\\\HDFS\\\\Data\\\\word2id_train.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blockid</th>\n",
       "      <th>EventSequence</th>\n",
       "      <th>labels</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>569963</td>\n",
       "      <td>blk_-8263499994297877702</td>\n",
       "      <td>[2, 2, 2, 12, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6,...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486412</td>\n",
       "      <td>blk_6623683650071326961</td>\n",
       "      <td>[2, 11, 2, 2, 3, 4, 3, 4, 3, 4, 5, 5, 14]</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171779</td>\n",
       "      <td>blk_2082025639925650040</td>\n",
       "      <td>[2, 2, 2, 12, 3, 4, 3, 4, 3, 4, 5, 5, 5, 9, 10...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224584</td>\n",
       "      <td>blk_5448888175997650632</td>\n",
       "      <td>[2, 2, 11, 2, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6,...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536913</td>\n",
       "      <td>blk_4492763112427066795</td>\n",
       "      <td>[2, 2, 11, 2, 3, 4, 3, 4, 3, 4, 5, 5, 14]</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460148</td>\n",
       "      <td>blk_1763114267597682207</td>\n",
       "      <td>[2, 11, 2, 2, 5, 3, 4, 3, 4, 3, 4, 5, 5, 6, 6,...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111571</td>\n",
       "      <td>blk_-8078410045005505674</td>\n",
       "      <td>[11, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 13, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462281</td>\n",
       "      <td>blk_-6694252843752535345</td>\n",
       "      <td>[2, 2, 11, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75704</td>\n",
       "      <td>blk_-8368340709610034828</td>\n",
       "      <td>[12, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 9, 9,...</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354799</td>\n",
       "      <td>blk_7199964155795817924</td>\n",
       "      <td>[2, 2, 12, 2, 3, 4, 3, 4, 3, 4, 5, 5, 14]</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460048 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Blockid  \\\n",
       "569963  blk_-8263499994297877702   \n",
       "486412   blk_6623683650071326961   \n",
       "171779   blk_2082025639925650040   \n",
       "224584   blk_5448888175997650632   \n",
       "536913   blk_4492763112427066795   \n",
       "...                          ...   \n",
       "460148   blk_1763114267597682207   \n",
       "111571  blk_-8078410045005505674   \n",
       "462281  blk_-6694252843752535345   \n",
       "75704   blk_-8368340709610034828   \n",
       "354799   blk_7199964155795817924   \n",
       "\n",
       "                                            EventSequence labels  Length  \n",
       "569963  [2, 2, 2, 12, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6,...      0      19  \n",
       "486412          [2, 11, 2, 2, 3, 4, 3, 4, 3, 4, 5, 5, 14]      0      13  \n",
       "171779  [2, 2, 2, 12, 3, 4, 3, 4, 3, 4, 5, 5, 5, 9, 10...      0      25  \n",
       "224584  [2, 2, 11, 2, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6,...      0      19  \n",
       "536913          [2, 2, 11, 2, 3, 4, 3, 4, 3, 4, 5, 5, 14]      0      13  \n",
       "...                                                   ...    ...     ...  \n",
       "460148  [2, 11, 2, 2, 5, 3, 4, 3, 4, 3, 4, 5, 5, 6, 6,...      0      19  \n",
       "111571  [11, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 13, 1...      0      25  \n",
       "462281                                     [2, 2, 11, 24]      1       4  \n",
       "75704   [12, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 9, 9,...      0      31  \n",
       "354799          [2, 2, 12, 2, 3, 4, 3, 4, 3, 4, 5, 5, 14]      0      13  \n",
       "\n",
       "[460048 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the data: 460048\n",
      "the size of the vocab: 97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blockid</th>\n",
       "      <th>EventSequence</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>446541</td>\n",
       "      <td>446541</td>\n",
       "      <td>446541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13507</td>\n",
       "      <td>13507</td>\n",
       "      <td>13507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Blockid  EventSequence  Length\n",
       "labels                                \n",
       "0        446541         446541  446541\n",
       "1         13507          13507   13507"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"the size of the data:\",len(train_data))\n",
    "print(\"the size of the vocab:\",len(word2id))\n",
    "train_data.groupby(['labels']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id['unknown']=len(word2id)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the updated vocab: 98\n"
     ]
    }
   ],
   "source": [
    "print(\"the size of the updated vocab:\",len(word2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blockid</th>\n",
       "      <th>EventSequence</th>\n",
       "      <th>labels</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>569963</td>\n",
       "      <td>blk_-8263499994297877702</td>\n",
       "      <td>[2, 2, 2, 12, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6,...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486412</td>\n",
       "      <td>blk_6623683650071326961</td>\n",
       "      <td>[2, 11, 2, 2, 3, 4, 3, 4, 3, 4, 5, 5, 14]</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171779</td>\n",
       "      <td>blk_2082025639925650040</td>\n",
       "      <td>[2, 2, 2, 12, 3, 4, 3, 4, 3, 4, 5, 5, 5, 9, 10...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224584</td>\n",
       "      <td>blk_5448888175997650632</td>\n",
       "      <td>[2, 2, 11, 2, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6,...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536913</td>\n",
       "      <td>blk_4492763112427066795</td>\n",
       "      <td>[2, 2, 11, 2, 3, 4, 3, 4, 3, 4, 5, 5, 14]</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Blockid  \\\n",
       "569963  blk_-8263499994297877702   \n",
       "486412   blk_6623683650071326961   \n",
       "171779   blk_2082025639925650040   \n",
       "224584   blk_5448888175997650632   \n",
       "536913   blk_4492763112427066795   \n",
       "\n",
       "                                            EventSequence labels  Length  \n",
       "569963  [2, 2, 2, 12, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6,...      0      19  \n",
       "486412          [2, 11, 2, 2, 3, 4, 3, 4, 3, 4, 5, 5, 14]      0      13  \n",
       "171779  [2, 2, 2, 12, 3, 4, 3, 4, 3, 4, 5, 5, 5, 9, 10...      0      25  \n",
       "224584  [2, 2, 11, 2, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6,...      0      19  \n",
       "536913          [2, 2, 11, 2, 3, 4, 3, 4, 3, 4, 5, 5, 14]      0      13  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blockid</th>\n",
       "      <th>EventSequence</th>\n",
       "      <th>labels</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>549142</td>\n",
       "      <td>blk_9030539814686132531</td>\n",
       "      <td>[2, 2, 12, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292808</td>\n",
       "      <td>blk_7717720559218514250</td>\n",
       "      <td>[2, 32]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87956</td>\n",
       "      <td>blk_-4397275276774729449</td>\n",
       "      <td>[12, 27]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62615</td>\n",
       "      <td>blk_6429121745702481909</td>\n",
       "      <td>[15, 27]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52885</td>\n",
       "      <td>blk_5567058207076986877</td>\n",
       "      <td>[15, 2, 2, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7209</td>\n",
       "      <td>blk_7165939739964393997</td>\n",
       "      <td>[11, 2, 2, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424987</td>\n",
       "      <td>blk_-6475794039385849761</td>\n",
       "      <td>[2, 33]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545982</td>\n",
       "      <td>blk_-6810082241294284349</td>\n",
       "      <td>[2, 33]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428480</td>\n",
       "      <td>blk_-2944709241310761499</td>\n",
       "      <td>[2, 2, 12, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462281</td>\n",
       "      <td>blk_-6694252843752535345</td>\n",
       "      <td>[2, 2, 11, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4967 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Blockid   EventSequence labels  Length\n",
       "549142   blk_9030539814686132531  [2, 2, 12, 24]      1       4\n",
       "292808   blk_7717720559218514250         [2, 32]      1       2\n",
       "87956   blk_-4397275276774729449        [12, 27]      1       2\n",
       "62615    blk_6429121745702481909        [15, 27]      1       2\n",
       "52885    blk_5567058207076986877  [15, 2, 2, 24]      1       4\n",
       "...                          ...             ...    ...     ...\n",
       "7209     blk_7165939739964393997  [11, 2, 2, 24]      1       4\n",
       "424987  blk_-6475794039385849761         [2, 33]      1       2\n",
       "545982  blk_-6810082241294284349         [2, 33]      1       2\n",
       "428480  blk_-2944709241310761499  [2, 2, 12, 24]      1       4\n",
       "462281  blk_-6694252843752535345  [2, 2, 11, 24]      1       4\n",
       "\n",
       "[4967 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['Length']<10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blockid</th>\n",
       "      <th>Preprocess_to_log_lines</th>\n",
       "      <th>labels</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>130892</td>\n",
       "      <td>blk_-7677011170870236960</td>\n",
       "      <td>[_info_dfs_fsnamesystem_block_namesystem_alloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174562</td>\n",
       "      <td>blk_6638067388838485468</td>\n",
       "      <td>[_info_dfs_datanode_dataxceiver_receiving_bloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45990</td>\n",
       "      <td>blk_-2587859430834379342</td>\n",
       "      <td>[_info_dfs_fsnamesystem_block_namesystem_alloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192504</td>\n",
       "      <td>blk_7519767082407935685</td>\n",
       "      <td>[_info_dfs_datanode_dataxceiver_receiving_bloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43736</td>\n",
       "      <td>blk_-2548681213192465965</td>\n",
       "      <td>[_info_dfs_fsnamesystem_block_namesystem_alloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Blockid  \\\n",
       "130892  blk_-7677011170870236960   \n",
       "174562   blk_6638067388838485468   \n",
       "45990   blk_-2587859430834379342   \n",
       "192504   blk_7519767082407935685   \n",
       "43736   blk_-2548681213192465965   \n",
       "\n",
       "                                  Preprocess_to_log_lines labels  Length  \n",
       "130892  [_info_dfs_fsnamesystem_block_namesystem_alloc...      0      23  \n",
       "174562  [_info_dfs_datanode_dataxceiver_receiving_bloc...      0      25  \n",
       "45990   [_info_dfs_fsnamesystem_block_namesystem_alloc...      0      20  \n",
       "192504  [_info_dfs_datanode_dataxceiver_receiving_bloc...      0      19  \n",
       "43736   [_info_dfs_fsnamesystem_block_namesystem_alloc...      0      19  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_pickle(\"C:\\\\Users\\\\A373503\\\\Desktop\\\\Complete_4_models\\\\HDFS\\\\Data\\\\HDFS_test_data.pkl\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the data: 115013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blockid</th>\n",
       "      <th>Preprocess_to_log_lines</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111682</td>\n",
       "      <td>111682</td>\n",
       "      <td>111682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3331</td>\n",
       "      <td>3331</td>\n",
       "      <td>3331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Blockid  Preprocess_to_log_lines  Length\n",
       "labels                                          \n",
       "0        111682                   111682  111682\n",
       "1          3331                     3331    3331"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"the size of the data:\",len(test_data))\n",
    "test_data.groupby(['labels']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of training data: 460048\n",
      "The size of test data: 115013\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of training data:\",len(train_data))\n",
    "print(\"The size of test data:\",len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here only for the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> To avoid ignoring the short lengths logs: padding on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_short_logs(data,window_size):\n",
    "    for i in range(len(data)):\n",
    "        if len(data.EventSequence.iloc[i]) < window_size+1:\n",
    "            data.EventSequence.iloc[i]=pad_sequences([data.EventSequence.iloc[i]], maxlen=window_size+1)[0]\n",
    "            #print(data.EventSequence.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "data=train_data\n",
    "window_size=10\n",
    "padding_short_logs(data,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blockid</th>\n",
       "      <th>EventSequence</th>\n",
       "      <th>labels</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>549142</td>\n",
       "      <td>blk_9030539814686132531</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 2, 2, 12, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292808</td>\n",
       "      <td>blk_7717720559218514250</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 32]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87956</td>\n",
       "      <td>blk_-4397275276774729449</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 27]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62615</td>\n",
       "      <td>blk_6429121745702481909</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 27]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52885</td>\n",
       "      <td>blk_5567058207076986877</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 15, 2, 2, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7209</td>\n",
       "      <td>blk_7165939739964393997</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 11, 2, 2, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424987</td>\n",
       "      <td>blk_-6475794039385849761</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 33]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545982</td>\n",
       "      <td>blk_-6810082241294284349</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 33]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428480</td>\n",
       "      <td>blk_-2944709241310761499</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 2, 2, 12, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462281</td>\n",
       "      <td>blk_-6694252843752535345</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 2, 2, 11, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4967 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Blockid                        EventSequence labels  \\\n",
       "549142   blk_9030539814686132531  [0, 0, 0, 0, 0, 0, 0, 2, 2, 12, 24]      1   \n",
       "292808   blk_7717720559218514250   [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 32]      1   \n",
       "87956   blk_-4397275276774729449  [0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 27]      1   \n",
       "62615    blk_6429121745702481909  [0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 27]      1   \n",
       "52885    blk_5567058207076986877  [0, 0, 0, 0, 0, 0, 0, 15, 2, 2, 24]      1   \n",
       "...                          ...                                  ...    ...   \n",
       "7209     blk_7165939739964393997  [0, 0, 0, 0, 0, 0, 0, 11, 2, 2, 24]      1   \n",
       "424987  blk_-6475794039385849761   [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 33]      1   \n",
       "545982  blk_-6810082241294284349   [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 33]      1   \n",
       "428480  blk_-2944709241310761499  [0, 0, 0, 0, 0, 0, 0, 2, 2, 12, 24]      1   \n",
       "462281  blk_-6694252843752535345  [0, 0, 0, 0, 0, 0, 0, 2, 2, 11, 24]      1   \n",
       "\n",
       "        Length  \n",
       "549142       4  \n",
       "292808       2  \n",
       "87956        2  \n",
       "62615        2  \n",
       "52885        4  \n",
       "...        ...  \n",
       "7209         4  \n",
       "424987       2  \n",
       "545982       2  \n",
       "428480       4  \n",
       "462281       4  \n",
       "\n",
       "[4967 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data[\"Length\"] < window_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "volab=len(word2id)\n",
    "def generate_within_blockid(data, window_size,step):\n",
    "    x = []\n",
    "    y = []\n",
    "    seq=[]\n",
    "    for i in range(len(data)):\n",
    "        for item in range(0,len(data[\"EventSequence\"].iloc[i])-window_size, step):\n",
    "            seq=data.EventSequence.iloc[i]\n",
    "            sentence=seq[item:item+window_size]\n",
    "            target=seq[item+window_size]\n",
    "                \n",
    "            x.append(sentence)\n",
    "            y.append(target)\n",
    "            \n",
    "    x=np.array(x)\n",
    "    y=to_categorical(y, volab+1)\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>take an example to look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sequence is: [[2, 2, 2, 12, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6, 6, 7, 7, 8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The first sequence is:\",list(train_data[:1].EventSequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then we do the function only on the first sequence\n",
    "X_n,y_n=generate_within_blockid(train_data[:1], window_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  2,  2, 12,  3,  4,  3,  4,  3,  4],\n",
       "       [ 2,  2, 12,  3,  4,  3,  4,  3,  4,  5],\n",
       "       [ 2, 12,  3,  4,  3,  4,  3,  4,  5,  5],\n",
       "       [12,  3,  4,  3,  4,  3,  4,  5,  5,  5],\n",
       "       [ 3,  4,  3,  4,  3,  4,  5,  5,  5,  6],\n",
       "       [ 4,  3,  4,  3,  4,  5,  5,  5,  6,  6],\n",
       "       [ 3,  4,  3,  4,  5,  5,  5,  6,  6,  6],\n",
       "       [ 4,  3,  4,  5,  5,  5,  6,  6,  6,  7],\n",
       "       [ 3,  4,  5,  5,  5,  6,  6,  6,  7,  7]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 6, 6, 6, 7, 7, 8], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_n,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a280ae4a1535>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerate_within_blockid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-4f4924a4c67b>\u001b[0m in \u001b[0;36mgenerate_within_blockid\u001b[1;34m(data, window_size, step)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"EventSequence\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mseq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEventSequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0msentence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5175\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5176\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5177\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5179\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X,y=generate_within_blockid(train_data, window_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X) #this is the size of the input of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix the testdata: \n",
    "<b>transform the logs into integers as the same in the vocab and if unknown logs are found, transfer those into <unknown>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blockid</th>\n",
       "      <th>Preprocess_to_log_lines</th>\n",
       "      <th>labels</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>130892</td>\n",
       "      <td>blk_-7677011170870236960</td>\n",
       "      <td>[_info_dfs_fsnamesystem_block_namesystem_alloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174562</td>\n",
       "      <td>blk_6638067388838485468</td>\n",
       "      <td>[_info_dfs_datanode_dataxceiver_receiving_bloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45990</td>\n",
       "      <td>blk_-2587859430834379342</td>\n",
       "      <td>[_info_dfs_fsnamesystem_block_namesystem_alloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192504</td>\n",
       "      <td>blk_7519767082407935685</td>\n",
       "      <td>[_info_dfs_datanode_dataxceiver_receiving_bloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43736</td>\n",
       "      <td>blk_-2548681213192465965</td>\n",
       "      <td>[_info_dfs_fsnamesystem_block_namesystem_alloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Blockid  \\\n",
       "130892  blk_-7677011170870236960   \n",
       "174562   blk_6638067388838485468   \n",
       "45990   blk_-2587859430834379342   \n",
       "192504   blk_7519767082407935685   \n",
       "43736   blk_-2548681213192465965   \n",
       "\n",
       "                                  Preprocess_to_log_lines labels  Length  \n",
       "130892  [_info_dfs_fsnamesystem_block_namesystem_alloc...      0      23  \n",
       "174562  [_info_dfs_datanode_dataxceiver_receiving_bloc...      0      25  \n",
       "45990   [_info_dfs_fsnamesystem_block_namesystem_alloc...      0      20  \n",
       "192504  [_info_dfs_datanode_dataxceiver_receiving_bloc...      0      19  \n",
       "43736   [_info_dfs_fsnamesystem_block_namesystem_alloc...      0      19  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{True: 1,\n",
       " '_info_dfs_datanode_dataxceiver_receiving_block_blk_src_dest_,': 2,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_for_block_blk_terminating,': 3,\n",
       " '_info_dfs_datanode_packetresponder_received_block_blk_of_size_from_,': 4,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_addstoredblock_blockmap_updated_is_added_to_blk_size_,': 5,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_delete_blk_is_added_to_invalidset_of_,': 6,\n",
       " '_info_dfs_fsdataset_deleting_block_blk_file_mnt_hadoop_dfs_data_current_subdir_blk_,': 7,\n",
       " '_info_dfs_fsdataset_deleting_block_blk_file_mnt_hadoop_dfs_data_current_subdir_blk_': 8,\n",
       " '_info_dfs_datanode_dataxceiver_served_block_blk_to_,': 9,\n",
       " '_warn_dfs_datanode_dataxceiver_got_exception_while_serving_blk_to_,': 10,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_rand_temporary_task_m_part_blk_,': 11,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_randtxt_temporary_task_m_part_blk_,': 12,\n",
       " '_info_dfs_datablockscanner_verification_succeeded_for_blk_,': 13,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_addstoredblock_blockmap_updated_is_added_to_blk_size_': 14,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_sortrand_temporary_task_r_part_blk_,': 15,\n",
       " '_info_dfs_fsdataset_deleting_block_blk_file_mnt_hadoop_dfs_data_current_blk_,': 16,\n",
       " '_info_dfs_fsdataset_deleting_block_blk_file_mnt_hadoop_dfs_data_current_blk_': 17,\n",
       " '_info_dfs_datanode_dataxceiver_received_block_blk_src_dest_of_size_,': 18,\n",
       " '_info_dfs_fsnamesystem_block_ask_to_replicate_blk_to_datanode_s_,': 19,\n",
       " '_info_dfs_datanode_starting_thread_to_transfer_block_blk_to_,': 20,\n",
       " '_info_dfs_datanode_datatransfer_transmitted_block_blk_to_,': 21,\n",
       " '_info_dfs_datablockscanner_verification_succeeded_for_blk_': 22,\n",
       " '_warn_dfs_fsdataset_unexpected_error_trying_to_delete_block_blk_blockinfo_not_found_in_volumemap_,': 23,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_io_ioexception_could_not_read_from_stream': 24,\n",
       " '_warn_dfs_fsdataset_unexpected_error_trying_to_delete_block_blk_blockinfo_not_found_in_volumemap_': 25,\n",
       " '_info_dfs_datanode_blockreceiver_receiving_empty_packet_for_block_blk_,': 26,\n",
       " '_info_dfs_datanode_dataxceiver_receiving_block_blk_src_dest_': 27,\n",
       " '_info_dfs_datanode_packetresponder_received_block_blk_of_size_from_': 28,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_addstoredblock_addstoredblock_request_received_for_blk_on_size_but_it_does_not_belong_to_any_file_,': 29,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_wcnt_temporary_task_r_part_blk_,': 30,\n",
       " '_warn_dfs_fsnamesystem_block_namesystem_addstoredblock_redundant_addstoredblock_request_received_for_blk_on_size_,': 31,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_rand_temporary_task_m_part_blk_': 32,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_randtxt_temporary_task_m_part_blk_': 33,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_for_block_blk_terminating': 34,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_sortrand_temporary_task_r_part_blk_': 35,\n",
       " '_info_dfs_datanode_blockreceiver_exception_in_receiveblock_for_block_blk_java_io_ioexception_connection_reset_by_peer,': 36,\n",
       " '_info_dfs_datanode_blockreceiver_changing_block_file_offset_of_block_blk_from_to_meta_file_offset_to_,': 37,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_io_ioexception_connection_reset_by_peer,': 38,\n",
       " '_warn_dfs_fsnamesystem_block_namesystem_addstoredblock_redundant_addstoredblock_request_received_for_blk_on_size_': 39,\n",
       " '_info_dfs_datanode_blockreceiver_exception_in_receiveblock_for_block_blk_java_io_eofexception,': 40,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_for_block_blk_interrupted_,': 41,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_io_eofexception,': 42,\n",
       " '_warn_dfs_pendingreplicationblocks_pendingreplicationmonitor_pendingreplicationmonitor_timed_out_block_blk_,': 43,\n",
       " '_info_dfs_datanode_blockreceiver_exception_writing_block_blk_to_mirror_,': 44,\n",
       " '_warn_dfs_datanode_dataxceiver_got_exception_while_serving_blk_to_': 45,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_blk_exception_java_io_interruptedioexception_interruped_while_waiting_for_io_on_channel_java_nio_channels_socketchannel_connected_local_remote_millis_timeout_left_,': 46,\n",
       " '_info_dfs_datanode_dataxceiver_served_block_blk_to_': 47,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_mnt_hadoop_mapred_system_job_job_jar_blk_,': 48,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_blk_exception_java_net_sockettimeoutexception_millis_timeout_while_waiting_for_channel_to_be_ready_for_read_ch_java_nio_channels_socketchannel_connected_local_remote_,': 49,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_mnt_hadoop_mapred_system_job_job_split_blk_,': 50,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_mnt_hadoop_mapred_system_job_job_xml_blk_,': 51,\n",
       " '_info_dfs_datanode_blockreceiver_exception_in_receiveblock_for_block_blk_java_io_interruptedioexception_interruped_while_waiting_for_io_on_channel_java_nio_channels_socketchannel_connected_local_remote_millis_timeout_left_,': 52,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_blk_exception_java_io_eofexception,': 53,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_io_ioexception_connection_reset_by_peer': 54,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_io_ioexception_interrupted_receiveblock,': 55,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_blk_exception_java_nio_channels_closedbyinterruptexception,': 56,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_blk_exception_java_io_ioexception_connection_reset_by_peer,': 57,\n",
       " '_warn_dfs_datanode_datatransfer_failed_to_transfer_blk_to_got_java_io_ioexception_connection_reset_by_peer,': 58,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_net_sockettimeoutexception_millis_timeout_while_waiting_for_channel_to_be_ready_for_read_ch_java_nio_channels_socketchannel_connected_local_remote_,': 59,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_net_sockettimeoutexception,': 60,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_io_ioexception_block_blk_is_valid_and_cannot_be_written_to_,': 61,\n",
       " '_warn_dfs_datablockscanner_adding_an_already_existing_block_blk_,': 62,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_rand_logs_history_ip_ec_internal_job_conf_xml_blk_,': 63,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_io_interruptedioexception_interruped_while_waiting_for_io_on_channel_java_nio_channels_socketchannel_connected_local_remote_millis_timeout_left_,': 64,\n",
       " '_info_dfs_datanode_blockreceiver_exception_in_receiveblock_for_block_blk_java_nio_channels_closedbyinterruptexception,': 65,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_blk_exception_java_io_ioexception_broken_pipe,': 66,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_nio_channels_closedbyinterruptexception,': 67,\n",
       " '_warn_dfs_pendingreplicationblocks_pendingreplicationmonitor_pendingreplicationmonitor_timed_out_block_blk_': 68,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_randtxt_logs_history_ip_ec_internal_job_conf_xml_blk_,': 69,\n",
       " '_info_dfs_fsdataset_reopen_block_blk_,': 70,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_blk_exception_java_io_interruptedioexception_interruped_while_waiting_for_io_on_channel_java_nio_channels_socketchannel_closed_millis_timeout_left_,': 71,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_rand_logs_history_ip_ec_internal_job_root_random_writer_blk_,': 72,\n",
       " '_info_dfs_fsnamesystem_block_removing_block_blk_from_neededreplications_as_it_does_not_belong_to_any_file_,': 73,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_blk_exception_java_io_interruptedioexception_interruped_while_waiting_for_io_on_channel_java_nio_channels_socketchannel_connected_local_remote_millis_timeout_left_': 74,\n",
       " '_info_dfs_datanode_blockreceiver_exception_in_receiveblock_for_block_blk_java_net_sockettimeoutexception_millis_timeout_while_waiting_for_channel_to_be_ready_for_write_ch_java_nio_channels_socketchannel_connected_local_remote_,': 75,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_net_sockettimeoutexception_millis_timeout_while_waiting_for_channel_to_be_ready_for_write_ch_java_nio_channels_socketchannel_connected_local_remote_,': 76,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_randtxt_logs_history_ip_ec_internal_job_root_random_text_writer_blk_,': 77,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_grep_temp_logs_history_ip_ec_internal_job_root_grep_search_blk_,': 78,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_grep_temp_logs_history_ip_ec_internal_job_conf_xml_blk_,': 79,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_wcnt_logs_history_ip_ec_internal_job_root_wordcount_blk_,': 80,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_sortrand_logs_history_ip_ec_internal_job_root_sorter_blk_,': 81,\n",
       " '_info_dfs_datanode_blockreceiver_exception_in_receiveblock_for_block_blk_java_io_ioexception_broken_pipe,': 82,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_io_ioexception_broken_pipe,': 83,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_io_ioexception_broken_pipe': 84,\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_blk_exception_java_io_ioexception_the_stream_is_closed,': 85,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_net_sockettimeoutexception': 86,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_grep_temp_temporary_task_r_part_blk_,': 87,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_grepb_logs_history_ip_ec_internal_job_conf_xml_blk_,': 88,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_io_ioexception_could_not_read_from_stream,': 89,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_grepa_logs_history_ip_ec_internal_job_conf_xml_blk_,': 90,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_rand_logs_history_ip_ec_internal_job_conf_xml_blk_': 91,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_grepb_logs_history_ip_ec_internal_job_root_grep_sort_blk_,': 92,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_sortrand_logs_history_ip_ec_internal_job_conf_xml_blk_,': 93,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_grepa_logs_history_ip_ec_internal_job_root_grep_sort_blk_,': 94,\n",
       " '_info_dfs_datanode_dataxceiver_writeblock_blk_received_exception_java_net_noroutetohostexception_no_route_to_host': 95,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_randtxt_logs_history_ip_ec_internal_job_root_random_writer_blk_,': 96,\n",
       " '_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_wcnt_logs_history_ip_ec_internal_job_conf_xml_blk_,': 97,\n",
       " 'unknown': 98}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inx=()\n",
    "forj=[]\n",
    "ends=[]\n",
    "for i in range(len(test_data)):\n",
    "\n",
    "    lists=test_data.Preprocess_to_log_lines.iloc[i]\n",
    "\n",
    "    for j in range(len(lists)):\n",
    "        \n",
    "        char=test_data.Preprocess_to_log_lines.iloc[i][j]\n",
    "        if char in word2id:\n",
    "            inx = word2id[char]\n",
    "        else:\n",
    "            inx = 98\n",
    "            \n",
    "        forj += [inx]\n",
    "        \n",
    "    ends+=[forj]\n",
    "    forj= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['EventSequence']=ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blockid</th>\n",
       "      <th>Preprocess_to_log_lines</th>\n",
       "      <th>labels</th>\n",
       "      <th>Length</th>\n",
       "      <th>EventSequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>130892</td>\n",
       "      <td>blk_-7677011170870236960</td>\n",
       "      <td>[_info_dfs_fsnamesystem_block_namesystem_alloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>[11, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 10, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174562</td>\n",
       "      <td>blk_6638067388838485468</td>\n",
       "      <td>[_info_dfs_datanode_dataxceiver_receiving_bloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>[2, 12, 2, 2, 3, 4, 3, 4, 3, 4, 5, 5, 5, 10, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45990</td>\n",
       "      <td>blk_-2587859430834379342</td>\n",
       "      <td>[_info_dfs_fsnamesystem_block_namesystem_alloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>[15, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 13, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192504</td>\n",
       "      <td>blk_7519767082407935685</td>\n",
       "      <td>[_info_dfs_datanode_dataxceiver_receiving_bloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[2, 2, 2, 15, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43736</td>\n",
       "      <td>blk_-2548681213192465965</td>\n",
       "      <td>[_info_dfs_fsnamesystem_block_namesystem_alloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[15, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 6, 6,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Blockid  \\\n",
       "130892  blk_-7677011170870236960   \n",
       "174562   blk_6638067388838485468   \n",
       "45990   blk_-2587859430834379342   \n",
       "192504   blk_7519767082407935685   \n",
       "43736   blk_-2548681213192465965   \n",
       "\n",
       "                                  Preprocess_to_log_lines labels  Length  \\\n",
       "130892  [_info_dfs_fsnamesystem_block_namesystem_alloc...      0      23   \n",
       "174562  [_info_dfs_datanode_dataxceiver_receiving_bloc...      0      25   \n",
       "45990   [_info_dfs_fsnamesystem_block_namesystem_alloc...      0      20   \n",
       "192504  [_info_dfs_datanode_dataxceiver_receiving_bloc...      0      19   \n",
       "43736   [_info_dfs_fsnamesystem_block_namesystem_alloc...      0      19   \n",
       "\n",
       "                                            EventSequence  \n",
       "130892  [11, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 10, 1...  \n",
       "174562  [2, 12, 2, 2, 3, 4, 3, 4, 3, 4, 5, 5, 5, 10, 9...  \n",
       "45990   [15, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 13, 6...  \n",
       "192504  [2, 2, 2, 15, 3, 4, 3, 4, 3, 4, 5, 5, 5, 6, 6,...  \n",
       "43736   [15, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 6, 6,...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_info_dfs_fsnamesystem_block_namesystem_allocateblock_user_root_rand_temporary_task_m_part_blk_,',\n",
       " '_info_dfs_datanode_dataxceiver_receiving_block_blk_src_dest_,',\n",
       " '_info_dfs_datanode_dataxceiver_receiving_block_blk_src_dest_,',\n",
       " '_info_dfs_datanode_dataxceiver_receiving_block_blk_src_dest_,',\n",
       " '_info_dfs_fsnamesystem_block_namesystem_addstoredblock_blockmap_updated_is_added_to_blk_size_,',\n",
       " '_info_dfs_fsnamesystem_block_namesystem_addstoredblock_blockmap_updated_is_added_to_blk_size_,',\n",
       " '_info_dfs_fsnamesystem_block_namesystem_addstoredblock_blockmap_updated_is_added_to_blk_size_,',\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_for_block_blk_terminating,',\n",
       " '_info_dfs_datanode_packetresponder_received_block_blk_of_size_from_,',\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_for_block_blk_terminating,',\n",
       " '_info_dfs_datanode_packetresponder_received_block_blk_of_size_from_,',\n",
       " '_info_dfs_datanode_packetresponder_packetresponder_for_block_blk_terminating,',\n",
       " '_info_dfs_datanode_packetresponder_received_block_blk_of_size_from_,',\n",
       " '_warn_dfs_datanode_dataxceiver_got_exception_while_serving_blk_to_,',\n",
       " '_warn_dfs_datanode_dataxceiver_got_exception_while_serving_blk_to_,',\n",
       " '_info_dfs_datanode_dataxceiver_served_block_blk_to_,',\n",
       " '_info_dfs_datablockscanner_verification_succeeded_for_blk_,',\n",
       " '_info_dfs_fsnamesystem_block_namesystem_delete_blk_is_added_to_invalidset_of_,',\n",
       " '_info_dfs_fsnamesystem_block_namesystem_delete_blk_is_added_to_invalidset_of_,',\n",
       " '_info_dfs_fsnamesystem_block_namesystem_delete_blk_is_added_to_invalidset_of_,',\n",
       " '_info_dfs_fsdataset_deleting_block_blk_file_mnt_hadoop_dfs_data_current_subdir_blk_,',\n",
       " '_info_dfs_fsdataset_deleting_block_blk_file_mnt_hadoop_dfs_data_current_subdir_blk_,',\n",
       " '_info_dfs_fsdataset_deleting_block_blk_file_mnt_hadoop_dfs_data_current_subdir_blk_']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.Preprocess_to_log_lines.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 2, 2, 2, 5, 5, 5, 3, 4, 3, 4, 3, 4, 10, 10, 9, 13, 6, 6, 6, 7, 7, 8]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.EventSequence.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>check the short lengths again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[test_data['Length']<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_short_logs(test_data,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[test_data[\"Length\"] < window_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_pickle(\"transformer_mix_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=generate_within_blockid(test_data[:23003], window_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test) #also, the output here is the size of the input data to do testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(volab+1, 128, input_length = window_size)) #input shape: [samples, steps, features]\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(volab+1, activation='softmax')) \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>validation_split</b>: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5,\n",
    "           patience=3, verbose=1)\n",
    "logs = Callback()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy',tf.keras.metrics.Recall(),tf.keras.metrics.Precision(),tf.keras.metrics.TruePositives(),tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives()])\n",
    "model.fit(X, y, batch_size=64, epochs=10,shuffle = True,validation_split = 0.1, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "#model.save('hdfs_05_09_mix_training.txt') #\n",
    "\n",
    "\n",
    "# load model\n",
    "model = load_model('hdfs_05_09_mix_training.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not run from here, try the fixed test data as transformer. 2021_05_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= pd.read_pickle(\"C:\\\\Users\\\\A373503\\\\Desktop\\\\Complete_4_models\\\\HDFS\\\\Transformer\\\\HDFS_test_data_for_all.pkl\")\n",
    "test_data.labels.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id['unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=generate_within_blockid(test_data, 10,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax output\n",
    "prediction = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=test_data[:23003]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point the target to the corresponding block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head() #overview the dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[test_data['Length'<11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.labels.value_counts() #here we will see how many anomalies in the testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeled_targets(data,window_size):\n",
    "    window_num=[]\n",
    "    for i in range(len(data)):        \n",
    "        window_n=len(data.EventSequence.iloc[i])-window_size\n",
    "        window_num.append(window_n)         \n",
    "    return window_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_num=labeled_targets(test_data,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the functions are correct\n",
    "print(\"sum of the window_num\",sum(window_num))\n",
    "print(\"window num of X_test\",len(X_test))\n",
    "##################################33\n",
    "#if the two values are same: no error step now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in window_num:\n",
    "    if i<1:\n",
    "        print(i)\n",
    "#make sure we do not have any negetive numbers\n",
    "#if we have the negetive number: we did not padding the short length logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Deeplog Method : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy overview \n",
    "accs=list()\n",
    "\n",
    "for i in range(1,20):\n",
    "    preds=(-prediction).argsort()[:,:i]\n",
    "    truth=(-y_test).argsort()[:,0]\n",
    "    truth=truth[:, None]\n",
    "    \n",
    "    acc=sum([truth[i] in preds[i] for i in range(len(truth))])/len(truth)  \n",
    "    accs.append(acc)   \n",
    "    \n",
    "x=np.arange(1,20)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(x,accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(sum([truth[j] in preds[j] for j in range(0,3)])/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "TN=0 #ture negative\n",
    "FP=0 #false positive\n",
    "FN=0 #false negative\n",
    "TP=0 #ture positive\n",
    "precision=0\n",
    "recall=0\n",
    "accuracy=0\n",
    "f1_score=0\n",
    "left=0\n",
    "right=0\n",
    "\n",
    "n=6\n",
    "\n",
    "preds=(-prediction).argsort()[:,:n]\n",
    "truth=(-y_test).argsort()[:,0]\n",
    "truth=truth[:, None]\n",
    "window_num.append(-1) #solve the first number issue\n",
    "\n",
    "for i in range(len(test_data)): #for each blocks\n",
    "\n",
    "    num_preds=window_num[i] #we have how many targets(prediction)\n",
    "\n",
    "    #print(num_preds, \"predicts in the\",i+1,\"th block \" )\n",
    "    #print(\"In this block, the lable should be\",test_data_small.Labels.iloc[i])   \n",
    "    window_num[-1]=-1\n",
    "    left+=window_num[i-1]\n",
    "    right+=window_num[i]\n",
    "       \n",
    "    if int(sum([truth[j] in preds[j] for j in range(left+1,right)])/window_num[i]) is not 1: # anomaly prediction\n",
    "        if int(test_data.labels.iloc[i]) == 1: #label is anomaly\n",
    "            \n",
    "            TP+=1\n",
    "        else: #label is normal\n",
    "            FP+=1\n",
    "            \n",
    "    if int(sum([truth[j] in preds[j] for j in range(left+1,right)])/window_num[i]) is 1: #normal prediction\n",
    "        if int(test_data.labels.iloc[i]) == 0: #label is normal\n",
    "            TN+=1\n",
    "        else: #label is anomaly\n",
    "            FN+=1\n",
    "            \n",
    "            \n",
    "\n",
    "    #here is to check all things are correct!!\n",
    "    #print(window_num[i],left+1,right)\n",
    "    if i == len(test_data)-1: \n",
    "        print(\"This print is to check all ranges are correct:\")\n",
    "        print(\"The range will be in\",left+1,'and',right,\"and the lenth of the targets in this block is\",window_num[i])\n",
    "        print(\" Round\",i+1,\" done!!!\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "                 \n",
    "        \n",
    "\n",
    "print(\"Top\",n,\":\")\n",
    "#print(\"We have\",len(test_data),\"blocks in total.\")\n",
    "#print(\"We have\",len(X_test),\"windows in total.\")\n",
    "print(\"True positive (anomaly label with anomaly prediction):\",TP)\n",
    "print(\"False positive (normal label with anomaly prediction):\",FP)\n",
    "print(\"False negative (anomaly label with normal prediction): \",FN)\n",
    "print(\"True negative (normal label with normal prediction):\",TN)\n",
    "            \n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "precision=TP/(TP+FP)\n",
    "recall=TP/(TP+FN)\n",
    "f1_score=(2*recall*precision)/(recall+precision)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F1 score:\",f1_score)\n",
    "print(\"---The runing time is: %s seconds ---\" % (time.time() - start_time))         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This print is to check all ranges are correct:\n",
    "The range will be in 1097453 and 1097462 and the lenth of the targets in this block is 9\n",
    " Round 115013  done!!!\n",
    "\n",
    "Top 6 :\n",
    "True positive (anomaly label with anomaly prediction): 149\n",
    "False positive (normal label with anomaly prediction): 130\n",
    "False negative (anomaly label with normal prediction):  3182\n",
    "True negative (normal label with normal prediction): 111552\n",
    "Accuracy: 0.9712032552841853\n",
    "Precision: 0.5340501792114696\n",
    "Recall: 0.04473131191834284\n",
    "F1 score: 0.08254847645429364\n",
    "---The runing time is: 13.718751668930054 seconds ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This print is to check all ranges are correct:\n",
    "The range will be in 218508 and 218521 and the lenth of the targets in this block is 13\n",
    " Round 23003  done!!!\n",
    "\n",
    "Top 6 :\n",
    "True positive (anomaly label with anomaly prediction): 654\n",
    "False positive (normal label with anomaly prediction): 436\n",
    "False negative (anomaly label with normal prediction):  2\n",
    "True negative (normal label with normal prediction): 21911\n",
    "Accuracy: 0.9809590053471287\n",
    "Precision: 0.6\n",
    "Recall: 0.9969512195121951\n",
    "F1 score: 0.7491408934707904\n",
    "---The runing time is: 2.5261642932891846 seconds ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
